{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5649f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T04:57:45.936473Z",
     "start_time": "2022-12-26T04:57:45.927457Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 19:10:31.396572: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 19:10:31.546069: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-23 19:10:32.096046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-23 19:10:32.096120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-23 19:10:32.096128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Text\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff78ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(model, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a3678",
   "metadata": {},
   "source": [
    "In this notebook, we will primarily focus on building a simple matrix factorization retrieval model powered by neuralCF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe89bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T04:45:16.431321Z",
     "start_time": "2022-12-26T04:45:16.369457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load final data from preprocessing_2_feature_engineering\n",
    "data = load_pickle('data_2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f7131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'age', 'gender', 'occupation', 'zipcode_bucket', 'movieId',\n",
       "       'imdb_id', 'title', 'movie_genre_1', 'movie_genre_2', 'IMDb_rating',\n",
       "       'plot embedding', 'release_year', 'rating', 'user_avg_rating',\n",
       "       'user_std_rating', 'user_rating_count', 'movie_avg_rating',\n",
       "       'movie_std_rating', 'movie_rating_count', 'user_fav_genre',\n",
       "       'user_fav_movieId', 'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83aa754f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T04:58:38.321640Z",
     "start_time": "2022-12-26T04:58:38.202036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load ratings and movies\n",
    "ratings =  data[['userId', 'imdb_id']]\n",
    "movies = data[['imdb_id']]\n",
    "ratings['userId'] = ratings.userId.astype(str)\n",
    "ratings['imdb_id'] = ratings.imdb_id.astype(str)\n",
    "movies['imdb_id'] = movies.imdb_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24938c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T04:58:40.083745Z",
     "start_time": "2022-12-26T04:58:40.064805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 19:10:34.353680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-23 19:10:34.353723: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-23 19:10:34.353766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-03-23 19:10:34.354183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load into tf datasets\n",
    "movies_ds = tf.data.Dataset.from_tensor_slices(dict(movies))\n",
    "ratings_ds = tf.data.Dataset.from_tensor_slices(dict(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a2ff0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:52:52.736452Z",
     "start_time": "2022-12-26T05:52:52.727474Z"
    }
   },
   "outputs": [],
   "source": [
    "# get training and testing dataset\n",
    "# shuffle and batch\n",
    "shuffled = ratings_ds.shuffle(100000, seed=32)\n",
    "\n",
    "train = shuffled.take(80000)\n",
    "test = shuffled.skip(80000).take(20000)\n",
    "\n",
    "cached_train = train.batch(128).cache()\n",
    "cached_test = test.batch(128).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad930034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T04:59:12.883716Z",
     "start_time": "2022-12-26T04:58:43.902373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build userId string lookup layer\n",
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings_ds.map(lambda x: x[\"userId\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38bc6b59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:00:32.052687Z",
     "start_time": "2022-12-26T05:00:01.295423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build movieId string lookup layer\n",
    "movie_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_ids_vocabulary.adapt(movies_ds.map(lambda x: x[\"imdb_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce03a311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:32:41.307725Z",
     "start_time": "2022-12-26T05:32:41.294766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define MovieLensModel model\n",
    "class MovieLensModel(tfrs.Model):\n",
    "\n",
    "    def __init__(\n",
    "                self,\n",
    "                user_model: tf.keras.Model,\n",
    "                movie_model: tf.keras.Model,\n",
    "                task: tfrs.tasks.Retrieval):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_model = user_model\n",
    "        self.movie_model = movie_model\n",
    "        self.task = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features[\"userId\"])\n",
    "        movie_embeddings = self.movie_model(features[\"imdb_id\"])\n",
    "\n",
    "        return self.task(user_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ca77bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:42:52.278337Z",
     "start_time": "2022-12-26T05:42:52.263203Z"
    }
   },
   "outputs": [],
   "source": [
    "# define user and movie models\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "\n",
    "\n",
    "])\n",
    "movie_model = tf.keras.Sequential([\n",
    "    movie_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(movie_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce89a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:53:04.320021Z",
     "start_time": "2022-12-26T05:53:04.289921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a neural collaborative filtering model\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\")\n",
    "\n",
    "])\n",
    "movie_model = tf.keras.Sequential([\n",
    "    movie_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(movie_ids_vocabulary.vocabulary_size(), 64),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc1fa0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T05:53:14.666231Z",
     "start_time": "2022-12-26T05:53:14.571556Z"
    }
   },
   "outputs": [],
   "source": [
    "# define metrics and task\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies_ds.map(lambda x: x[\"imdb_id\"]).batch(128).map(movie_model),\n",
    "  ks = (1, 5),\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(num_hard_negatives = 2, remove_accidental_hits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b199aa57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:02:36.545696Z",
     "start_time": "2022-12-26T05:53:20.894440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 3ms/step - loss: 140.6235 - regularization_loss: 0.0000e+00 - total_loss: 140.6235\n"
     ]
    }
   ],
   "source": [
    "# compile and train\n",
    "model = MovieLensModel(user_model, movie_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model_history = model.fit(cached_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7145b4f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:09:27.060654Z",
     "start_time": "2022-12-26T06:08:52.644591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 1s 3ms/step - loss: 140.1465 - regularization_loss: 0.0000e+00 - total_loss: 140.1465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 103.26954650878906,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 103.26954650878906}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0122f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
